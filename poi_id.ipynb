{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifying Fraud from Enron Financial Data and Email Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle\n",
    "sys.path.append(\"tools/\")\n",
    "\n",
    "import warnings\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "from tester import test_classifier, dump_classifier_and_data\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.mode.use_inf_as_na = True\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By 2002, Enron, one of America's most successful companies of the 1990s and 2000s, had been suspended from the New York Stock Exchange and was being investigated by the Department of Justice.  Once trading at a peak of \\$90.75, Enron's shares plummeted to $0.26 on December 2, 2001, when it declared bankruptcy.  At the time, Enron’s bankruptcy was the largest in U.S. history.  As a result, many executives at Enron were indicted and sentenced to prison time.  Enron used high-risk accounting practices that were meant to make the organization look more successful that it actually was in order to defraud shareholders.   Enron used mark-to-market accounting which used projected future earnings to measure the value of an asset, and if its value did not meet predictions they would hide the financial losses by assigning them to a shell company.\n",
    "\n",
    "The goal of this project is to determine from the financial and email metadata features in the data set which of the employees are persons of interest in the fraud case against Enron.  Persons of interest are defined as individuals who were indicted in the fraud, reached a settlement or plea deal with the government, or testified in exchange for immunity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dictionary containing the dataset\n",
    "with open(\"final_project_dataset.pkl\", \"rb\") as data_file:\n",
    "    data_dict = pickle.load(data_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bonus</th>\n",
       "      <th>deferral_payments</th>\n",
       "      <th>deferred_income</th>\n",
       "      <th>director_fees</th>\n",
       "      <th>email_address</th>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <th>expenses</th>\n",
       "      <th>from_messages</th>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <th>...</th>\n",
       "      <th>long_term_incentive</th>\n",
       "      <th>other</th>\n",
       "      <th>poi</th>\n",
       "      <th>restricted_stock</th>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <th>salary</th>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "      <th>to_messages</th>\n",
       "      <th>total_payments</th>\n",
       "      <th>total_stock_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ALLEN PHILLIP K</th>\n",
       "      <td>4175000</td>\n",
       "      <td>2869717</td>\n",
       "      <td>-3081055</td>\n",
       "      <td>NaN</td>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "      <td>1729541</td>\n",
       "      <td>13868</td>\n",
       "      <td>2195</td>\n",
       "      <td>47</td>\n",
       "      <td>65</td>\n",
       "      <td>...</td>\n",
       "      <td>304805</td>\n",
       "      <td>152</td>\n",
       "      <td>False</td>\n",
       "      <td>126027</td>\n",
       "      <td>-126027</td>\n",
       "      <td>201955</td>\n",
       "      <td>1407</td>\n",
       "      <td>2902</td>\n",
       "      <td>4484442</td>\n",
       "      <td>1729541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BADUM JAMES P</th>\n",
       "      <td>NaN</td>\n",
       "      <td>178980</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>257817</td>\n",
       "      <td>3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>182466</td>\n",
       "      <td>257817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BANNANTINE JAMES M</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-5104</td>\n",
       "      <td>NaN</td>\n",
       "      <td>james.bannantine@enron.com</td>\n",
       "      <td>4046157</td>\n",
       "      <td>56301</td>\n",
       "      <td>29</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>864523</td>\n",
       "      <td>False</td>\n",
       "      <td>1757552</td>\n",
       "      <td>-560222</td>\n",
       "      <td>477</td>\n",
       "      <td>465</td>\n",
       "      <td>566</td>\n",
       "      <td>916197</td>\n",
       "      <td>5243487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAXTER JOHN C</th>\n",
       "      <td>1200000</td>\n",
       "      <td>1295738</td>\n",
       "      <td>-1386055</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6680544</td>\n",
       "      <td>11200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1586055</td>\n",
       "      <td>2660303</td>\n",
       "      <td>False</td>\n",
       "      <td>3942714</td>\n",
       "      <td>NaN</td>\n",
       "      <td>267102</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5634343</td>\n",
       "      <td>10623258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAY FRANKLIN R</th>\n",
       "      <td>400000</td>\n",
       "      <td>260455</td>\n",
       "      <td>-201641</td>\n",
       "      <td>NaN</td>\n",
       "      <td>frank.bay@enron.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>129142</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69</td>\n",
       "      <td>False</td>\n",
       "      <td>145796</td>\n",
       "      <td>-82782</td>\n",
       "      <td>239671</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>827696</td>\n",
       "      <td>63014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      bonus deferral_payments deferred_income director_fees  \\\n",
       "ALLEN PHILLIP K     4175000           2869717        -3081055           NaN   \n",
       "BADUM JAMES P           NaN            178980             NaN           NaN   \n",
       "BANNANTINE JAMES M      NaN               NaN           -5104           NaN   \n",
       "BAXTER JOHN C       1200000           1295738        -1386055           NaN   \n",
       "BAY FRANKLIN R       400000            260455         -201641           NaN   \n",
       "\n",
       "                                 email_address exercised_stock_options  \\\n",
       "ALLEN PHILLIP K        phillip.allen@enron.com                 1729541   \n",
       "BADUM JAMES P                              NaN                  257817   \n",
       "BANNANTINE JAMES M  james.bannantine@enron.com                 4046157   \n",
       "BAXTER JOHN C                              NaN                 6680544   \n",
       "BAY FRANKLIN R             frank.bay@enron.com                     NaN   \n",
       "\n",
       "                   expenses from_messages from_poi_to_this_person  \\\n",
       "ALLEN PHILLIP K       13868          2195                      47   \n",
       "BADUM JAMES P          3486           NaN                     NaN   \n",
       "BANNANTINE JAMES M    56301            29                      39   \n",
       "BAXTER JOHN C         11200           NaN                     NaN   \n",
       "BAY FRANKLIN R       129142           NaN                     NaN   \n",
       "\n",
       "                   from_this_person_to_poi        ...         \\\n",
       "ALLEN PHILLIP K                         65        ...          \n",
       "BADUM JAMES P                          NaN        ...          \n",
       "BANNANTINE JAMES M                       0        ...          \n",
       "BAXTER JOHN C                          NaN        ...          \n",
       "BAY FRANKLIN R                         NaN        ...          \n",
       "\n",
       "                   long_term_incentive    other    poi restricted_stock  \\\n",
       "ALLEN PHILLIP K                 304805      152  False           126027   \n",
       "BADUM JAMES P                      NaN      NaN  False              NaN   \n",
       "BANNANTINE JAMES M                 NaN   864523  False          1757552   \n",
       "BAXTER JOHN C                  1586055  2660303  False          3942714   \n",
       "BAY FRANKLIN R                     NaN       69  False           145796   \n",
       "\n",
       "                   restricted_stock_deferred  salary shared_receipt_with_poi  \\\n",
       "ALLEN PHILLIP K                      -126027  201955                    1407   \n",
       "BADUM JAMES P                            NaN     NaN                     NaN   \n",
       "BANNANTINE JAMES M                   -560222     477                     465   \n",
       "BAXTER JOHN C                            NaN  267102                     NaN   \n",
       "BAY FRANKLIN R                        -82782  239671                     NaN   \n",
       "\n",
       "                   to_messages total_payments total_stock_value  \n",
       "ALLEN PHILLIP K           2902        4484442           1729541  \n",
       "BADUM JAMES P              NaN         182466            257817  \n",
       "BANNANTINE JAMES M         566         916197           5243487  \n",
       "BAXTER JOHN C              NaN        5634343          10623258  \n",
       "BAY FRANKLIN R             NaN         827696             63014  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data into a dataframe for exploration\n",
    "df = pd.DataFrame.from_dict(data_dict).T\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of records\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bonus</th>\n",
       "      <th>deferral_payments</th>\n",
       "      <th>deferred_income</th>\n",
       "      <th>director_fees</th>\n",
       "      <th>email_address</th>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <th>expenses</th>\n",
       "      <th>from_messages</th>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <th>...</th>\n",
       "      <th>long_term_incentive</th>\n",
       "      <th>other</th>\n",
       "      <th>poi</th>\n",
       "      <th>restricted_stock</th>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <th>salary</th>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "      <th>to_messages</th>\n",
       "      <th>total_payments</th>\n",
       "      <th>total_stock_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ALLEN PHILLIP K</th>\n",
       "      <td>4175000.0</td>\n",
       "      <td>2869717.0</td>\n",
       "      <td>-3081055.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "      <td>1729541.0</td>\n",
       "      <td>13868.0</td>\n",
       "      <td>2195.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>...</td>\n",
       "      <td>304805.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>False</td>\n",
       "      <td>126027.0</td>\n",
       "      <td>-126027.0</td>\n",
       "      <td>201955.0</td>\n",
       "      <td>1407.0</td>\n",
       "      <td>2902.0</td>\n",
       "      <td>4484442.0</td>\n",
       "      <td>1729541.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BADUM JAMES P</th>\n",
       "      <td>NaN</td>\n",
       "      <td>178980.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>257817.0</td>\n",
       "      <td>3486.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>182466.0</td>\n",
       "      <td>257817.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BANNANTINE JAMES M</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-5104.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>james.bannantine@enron.com</td>\n",
       "      <td>4046157.0</td>\n",
       "      <td>56301.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>864523.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1757552.0</td>\n",
       "      <td>-560222.0</td>\n",
       "      <td>477.0</td>\n",
       "      <td>465.0</td>\n",
       "      <td>566.0</td>\n",
       "      <td>916197.0</td>\n",
       "      <td>5243487.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAXTER JOHN C</th>\n",
       "      <td>1200000.0</td>\n",
       "      <td>1295738.0</td>\n",
       "      <td>-1386055.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>6680544.0</td>\n",
       "      <td>11200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1586055.0</td>\n",
       "      <td>2660303.0</td>\n",
       "      <td>False</td>\n",
       "      <td>3942714.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>267102.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5634343.0</td>\n",
       "      <td>10623258.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAY FRANKLIN R</th>\n",
       "      <td>400000.0</td>\n",
       "      <td>260455.0</td>\n",
       "      <td>-201641.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>frank.bay@enron.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>129142.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69.0</td>\n",
       "      <td>False</td>\n",
       "      <td>145796.0</td>\n",
       "      <td>-82782.0</td>\n",
       "      <td>239671.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>827696.0</td>\n",
       "      <td>63014.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        bonus  deferral_payments  deferred_income  \\\n",
       "ALLEN PHILLIP K     4175000.0          2869717.0       -3081055.0   \n",
       "BADUM JAMES P             NaN           178980.0              NaN   \n",
       "BANNANTINE JAMES M        NaN                NaN          -5104.0   \n",
       "BAXTER JOHN C       1200000.0          1295738.0       -1386055.0   \n",
       "BAY FRANKLIN R       400000.0           260455.0        -201641.0   \n",
       "\n",
       "                    director_fees               email_address  \\\n",
       "ALLEN PHILLIP K               NaN     phillip.allen@enron.com   \n",
       "BADUM JAMES P                 NaN                               \n",
       "BANNANTINE JAMES M            NaN  james.bannantine@enron.com   \n",
       "BAXTER JOHN C                 NaN                               \n",
       "BAY FRANKLIN R                NaN         frank.bay@enron.com   \n",
       "\n",
       "                    exercised_stock_options  expenses  from_messages  \\\n",
       "ALLEN PHILLIP K                   1729541.0   13868.0         2195.0   \n",
       "BADUM JAMES P                      257817.0    3486.0            NaN   \n",
       "BANNANTINE JAMES M                4046157.0   56301.0           29.0   \n",
       "BAXTER JOHN C                     6680544.0   11200.0            NaN   \n",
       "BAY FRANKLIN R                          NaN  129142.0            NaN   \n",
       "\n",
       "                    from_poi_to_this_person  from_this_person_to_poi  \\\n",
       "ALLEN PHILLIP K                        47.0                     65.0   \n",
       "BADUM JAMES P                           NaN                      NaN   \n",
       "BANNANTINE JAMES M                     39.0                      0.0   \n",
       "BAXTER JOHN C                           NaN                      NaN   \n",
       "BAY FRANKLIN R                          NaN                      NaN   \n",
       "\n",
       "                          ...          long_term_incentive      other    poi  \\\n",
       "ALLEN PHILLIP K           ...                     304805.0      152.0  False   \n",
       "BADUM JAMES P             ...                          NaN        NaN  False   \n",
       "BANNANTINE JAMES M        ...                          NaN   864523.0  False   \n",
       "BAXTER JOHN C             ...                    1586055.0  2660303.0  False   \n",
       "BAY FRANKLIN R            ...                          NaN       69.0  False   \n",
       "\n",
       "                    restricted_stock  restricted_stock_deferred    salary  \\\n",
       "ALLEN PHILLIP K             126027.0                  -126027.0  201955.0   \n",
       "BADUM JAMES P                    NaN                        NaN       NaN   \n",
       "BANNANTINE JAMES M         1757552.0                  -560222.0     477.0   \n",
       "BAXTER JOHN C              3942714.0                        NaN  267102.0   \n",
       "BAY FRANKLIN R              145796.0                   -82782.0  239671.0   \n",
       "\n",
       "                    shared_receipt_with_poi  to_messages  total_payments  \\\n",
       "ALLEN PHILLIP K                      1407.0       2902.0       4484442.0   \n",
       "BADUM JAMES P                           NaN          NaN        182466.0   \n",
       "BANNANTINE JAMES M                    465.0        566.0        916197.0   \n",
       "BAXTER JOHN C                           NaN          NaN       5634343.0   \n",
       "BAY FRANKLIN R                          NaN          NaN        827696.0   \n",
       "\n",
       "                    total_stock_value  \n",
       "ALLEN PHILLIP K             1729541.0  \n",
       "BADUM JAMES P                257817.0  \n",
       "BANNANTINE JAMES M          5243487.0  \n",
       "BAXTER JOHN C              10623258.0  \n",
       "BAY FRANKLIN R                63014.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace 'NaN' in email_address field with empty string\n",
    "df['email_address'].replace(to_replace='NaN', value = '', inplace=True)\n",
    "\n",
    "# Replace all other 'NaN' with NaN \n",
    "df.replace(to_replace='NaN', value = np.nan, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bonus                        float64\n",
       "deferral_payments            float64\n",
       "deferred_income              float64\n",
       "director_fees                float64\n",
       "email_address                 object\n",
       "exercised_stock_options      float64\n",
       "expenses                     float64\n",
       "from_messages                float64\n",
       "from_poi_to_this_person      float64\n",
       "from_this_person_to_poi      float64\n",
       "loan_advances                float64\n",
       "long_term_incentive          float64\n",
       "other                        float64\n",
       "poi                             bool\n",
       "restricted_stock             float64\n",
       "restricted_stock_deferred    float64\n",
       "salary                       float64\n",
       "shared_receipt_with_poi      float64\n",
       "to_messages                  float64\n",
       "total_payments               float64\n",
       "total_stock_value            float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.apply(lambda x: pd.to_numeric(x, errors='ignore'))\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    }
   ],
   "source": [
    "# Number of features\n",
    "print(len(list(df.columns)))\n",
    "target = 'poi'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a total of 21 fields, 14 financial features, 6 features concerning email metadata, and the target field poi.\n",
    "\n",
    "**financial features**\n",
    "* bonus\n",
    "* deferral_payments\n",
    "* deferred_income\n",
    "* director_fees\n",
    "* exercised_stock_options\n",
    "* expenses\n",
    "* loan_advances\n",
    "* long_term_incentive\n",
    "* other\n",
    "* restricted_stock\n",
    "* restricted_stock_deferred\n",
    "* salary\n",
    "* total_payments\n",
    "* total_stock_value\n",
    "\n",
    "**email features**\n",
    "* email_address\n",
    "* from_messages\n",
    "* from_poi_to_this_person\n",
    "* from_this_person_to_poi\n",
    "* shared_receipt_with_poi\n",
    "* to_messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BLAKE JR. NORMAN P',\n",
       " 'BOWEN JR RAYMOND M',\n",
       " 'DERRICK JR. JAMES V',\n",
       " 'DONAHUE JR JEFFREY M',\n",
       " 'GARLAND C KEVIN',\n",
       " 'GLISAN JR BEN F',\n",
       " 'OVERDYKE JR JERE C',\n",
       " 'PEREIRA PAULO V. FERRAZ',\n",
       " 'SULLIVAN-SHAKLOVITZ COLLEEN',\n",
       " 'THE TRAVEL AGENCY IN THE PARK',\n",
       " 'TOTAL',\n",
       " 'WALLS JR ROBERT H',\n",
       " 'WHITE JR THOMAS E',\n",
       " 'WINOKUR JR. HERBERT S',\n",
       " 'YEAGER F SCOTT']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Appropriate formats for names\n",
    "name_fmt_1 = '\\w+ \\w+ \\w'\n",
    "name_fmt_2 = '\\w+ \\w+'\n",
    "\n",
    "# Print names that do not follow either of these formats\n",
    "[p for p in df.index if not (re.fullmatch(name_fmt_1, p) or re.fullmatch(name_fmt_2, p))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BLAKE JR NORMAN P',\n",
       " 'BOWEN JR RAYMOND M',\n",
       " 'DERRICK JR JAMES V',\n",
       " 'DONAHUE JR JEFFREY M',\n",
       " 'GARLAND C KEVIN',\n",
       " 'GLISAN JR BEN F',\n",
       " 'OVERDYKE JR JERE C',\n",
       " 'PEREIRA PAULO V FERRAZ',\n",
       " 'SULLIVAN-SHAKLOVITZ COLLEEN',\n",
       " 'THE TRAVEL AGENCY IN THE PARK',\n",
       " 'TOTAL',\n",
       " 'WALLS JR ROBERT H',\n",
       " 'WHITE JR THOMAS E',\n",
       " 'WINOKUR JR HERBERT S',\n",
       " 'YEAGER F SCOTT']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove periods from names to make them consistent\n",
    "df.index = df.index.map(lambda x: x.replace('.', ''))\n",
    "\n",
    "[p for p in df.index if not (re.fullmatch(name_fmt_1, p) or re.fullmatch(name_fmt_2, p))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apart from the names with 'JR', additional middle names, a first initial, or a hyphenated last name, which are also acceptable, there are the records 'TOTAL' and 'THE TRAVEL AGENCY IN THE PARK'.  Obviously these records were included in the data set in error since they do not represent employees.  Below, inspection of the data confirms that 'TOTAL' is an aggregate row of all employees and was erroneously included in the data.  These records will be removed from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TOTAL'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['salary'].idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['salary'].max() == df['salary'].sum() - df['salary'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop non-employee records\n",
    "df.drop(['THE TRAVEL AGENCY IN THE PARK', 'TOTAL'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also chose to remove 'email_address' from the features since it cannot and will not be used to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove email since it is basically equivalent to an ID and cannot be used in the model\n",
    "df.drop('email_address', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bonus                         63\n",
       "deferral_payments            106\n",
       "deferred_income               96\n",
       "director_fees                128\n",
       "exercised_stock_options       43\n",
       "expenses                      50\n",
       "from_messages                 58\n",
       "from_poi_to_this_person       58\n",
       "from_this_person_to_poi       58\n",
       "loan_advances                141\n",
       "long_term_incentive           79\n",
       "other                         53\n",
       "poi                            0\n",
       "restricted_stock              35\n",
       "restricted_stock_deferred    127\n",
       "salary                        50\n",
       "shared_receipt_with_poi       58\n",
       "to_messages                   58\n",
       "total_payments                21\n",
       "total_stock_value             19\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data set has a lot of missing values, especially for many of the financial features.  Since there are so few records, it would not be appropriate to remove too many rows or columns from this data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LOCKHART EUGENE E         19\n",
       "WROBEL BRUCE              17\n",
       "WODRASKA JOHN             17\n",
       "GRAMM WENDY L             17\n",
       "WHALEY DAVID A            17\n",
       "SCRIMSHAW MATTHEW         17\n",
       "SAVAGE FRANK              16\n",
       "GILLIS JOHN               16\n",
       "WAKEHAM JOHN              16\n",
       "CHRISTODOULOU DIOMEDES    16\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum(axis = 1).sort_values(ascending = False)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'LOCKHART EUGENE E' has all fields missing except for poi, so he has been removed from the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('LOCKHART EUGENE E', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in missing values with 0\n",
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many of the financial features have a lot of missing values.  For instance, less than 15% of records have non-null values for the features ‘director_fees’, ‘loan_advances’, and ‘restricted_stock_deferred’.  Many of the nulls in the financial features are due to errors in data wrangling.  In the data source, many zero values are represented as ‘-‘, and were incorrectly interpreted as ‘NaN’.  Additionally, many of the features are aggregations of others, so using imputation to replace missing values would affect multiple features.  Hence, I chose to replace all missing values with zeros, except email addresses which were replaced with an empty string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of pois in the data set\n",
    "df['poi'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are only 18 positive instances out of 146 total records in the data set which means that this model will have to deal with class imbalance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bonus',\n",
       " 'deferral_payments',\n",
       " 'deferred_income',\n",
       " 'director_fees',\n",
       " 'exercised_stock_options',\n",
       " 'expenses',\n",
       " 'from_messages',\n",
       " 'from_poi_to_this_person',\n",
       " 'from_this_person_to_poi',\n",
       " 'loan_advances',\n",
       " 'long_term_incentive',\n",
       " 'other',\n",
       " 'restricted_stock',\n",
       " 'restricted_stock_deferred',\n",
       " 'salary',\n",
       " 'shared_receipt_with_poi',\n",
       " 'to_messages',\n",
       " 'total_payments',\n",
       " 'total_stock_value',\n",
       " 'prop_poi_communication',\n",
       " 'shared_receipt_with_poi_prop',\n",
       " 'bonus_prop',\n",
       " 'other_prop',\n",
       " 'expenses_prop',\n",
       " 'exercised_stock_options_prop',\n",
       " 'restricted_stock_prop']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These feature describes the proportion of communication that involves persons of interest\n",
    "df['prop_poi_communication'] = (df['from_poi_to_this_person'] + df['from_this_person_to_poi']) / \\\n",
    "                               (df['to_messages'] + df['from_messages'])\n",
    "df['shared_receipt_with_poi_prop'] = df['shared_receipt_with_poi'] / (df['to_messages'] + df['from_messages'])\n",
    "\n",
    "# These features describe the proportion of total_payments that each individual feature is\n",
    "df['bonus_prop'] = df['bonus'] / df['total_payments']\n",
    "df['other_prop'] = df['other'] / df['total_payments']\n",
    "df['expenses_prop'] = df['expenses'] / df['total_payments']\n",
    "\n",
    "# These features describe the proportion of total_stock_value that each individual feature is\n",
    "df['exercised_stock_options_prop'] = df['exercised_stock_options'] / df['total_stock_value']\n",
    "df['restricted_stock_prop'] = df['restricted_stock'] / df['total_stock_value']\n",
    "\n",
    "# Get new features list\n",
    "all_features = [feat for feat in list(df.columns) if feat != 'poi']\n",
    "all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After possible division by zero fill inf and -inf with 0\n",
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(24.815079733218194, 'exercised_stock_options'),\n",
       " (24.182898678566879, 'total_stock_value'),\n",
       " (20.792252047181535, 'bonus'),\n",
       " (20.715596247559954, 'bonus_prop'),\n",
       " (18.289684043404513, 'salary'),\n",
       " (11.458476579280369, 'deferred_income'),\n",
       " (9.9221860131898225, 'long_term_incentive'),\n",
       " (9.736968287824979, 'shared_receipt_with_poi_prop'),\n",
       " (9.2128106219771002, 'restricted_stock'),\n",
       " (8.7727777300916756, 'total_payments'),\n",
       " (8.589420731682381, 'shared_receipt_with_poi'),\n",
       " (7.1840556582887247, 'loan_advances'),\n",
       " (6.0941733106389453, 'expenses'),\n",
       " (5.399370288094401, 'prop_poi_communication'),\n",
       " (5.2434497133749582, 'from_poi_to_this_person'),\n",
       " (4.1874775069953749, 'other'),\n",
       " (2.3826121082276739, 'from_this_person_to_poi'),\n",
       " (2.1263278020077054, 'director_fees'),\n",
       " (1.6463411294420076, 'to_messages'),\n",
       " (1.0901571696328429, 'restricted_stock_prop'),\n",
       " (1.0684733217820632, 'other_prop'),\n",
       " (0.22461127473600989, 'deferral_payments'),\n",
       " (0.16970094762175533, 'from_messages'),\n",
       " (0.065499652909942141, 'restricted_stock_deferred'),\n",
       " (0.04211676849806735, 'exercised_stock_options_prop'),\n",
       " (0.017509612462176017, 'expenses_prop')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_selector = SelectKBest(f_classif, k='all').fit(df[all_features], df[target])\n",
    "feat_scores = list(zip(feature_selector.scores_, df[all_features].columns[feature_selector.get_support()]))\n",
    "feat_scores.sort(key=lambda tup: tup[0], reverse = True)\n",
    "feat_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of the features in order of their importance\n",
    "feats_sorted = [tup[1] for tup in feat_scores]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic classification function that returns training and validation metrics\n",
    "def classify(model, data, features, target):\n",
    "\n",
    "    skf = StratifiedShuffleSplit(n_splits=10, random_state = 42)\n",
    "    \n",
    "    tr_metrics = {}\n",
    "    val_metrics = {}\n",
    "    \n",
    "    metric_names = ['acc', 'prec', 'recall', 'f1']\n",
    "\n",
    "    for name in metric_names:\n",
    "            tr_metrics[name] = []\n",
    "            val_metrics[name] = []\n",
    "            \n",
    "    for train, test in skf.split(data[features], data[target]):\n",
    "        X_tr = (data[features].iloc[train,:])\n",
    "        y_tr = data[target].iloc[train]\n",
    "        X_val = data[features].iloc[test,:]\n",
    "        y_val = data[target].iloc[test]\n",
    "\n",
    "        # Train the model and record metrics\n",
    "        model.fit(X_tr, y_tr)\n",
    "        pred_tr = model.predict(X_tr)\n",
    "            \n",
    "        tr_metrics['acc'].append(accuracy_score(pred_tr, y_tr))\n",
    "        tr_metrics['prec'].append(precision_score(pred_tr, y_tr))\n",
    "        tr_metrics['recall'].append(recall_score(pred_tr, y_tr))\n",
    "        tr_metrics['f1'].append(f1_score(pred_tr, y_tr))\n",
    "\n",
    "        # Make predictions on the validation set and record metrics\n",
    "        pred = model.predict(X_val)\n",
    "        \n",
    "        val_metrics['acc'].append(accuracy_score(pred, y_val))\n",
    "        val_metrics['prec'].append(precision_score(pred, y_val))\n",
    "        val_metrics['recall'].append(recall_score(pred, y_val))\n",
    "        val_metrics['f1'].append(f1_score(pred, y_val))\n",
    "    \n",
    "    tr_mean_metrics = []\n",
    "    val_mean_metrics = []\n",
    "\n",
    "    # Only keep averages\n",
    "    for name in metric_names:\n",
    "        tr_mean_metrics.append(np.mean(tr_metrics[name]))\n",
    "        val_mean_metrics.append(np.mean(val_metrics[name]))\n",
    "        \n",
    "    return tr_mean_metrics, val_mean_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the classifier for 1:num_feat number of features\n",
    "def model_by_num_feat(model, data, features, target, num_feat):\n",
    "    tr_metrics_feat = {}\n",
    "    val_metrics_feat = {}\n",
    "    for i in range(1, num_feat + 1):\n",
    "        tr_metrics, val_metrics = classify(model, data, features[:i], target)\n",
    "        tr_metrics_feat[i] = tr_metrics\n",
    "        val_metrics_feat[i] = val_metrics\n",
    "\n",
    "    tr_metrics_df = pd.DataFrame(tr_metrics_feat).T\n",
    "    tr_metrics_df.columns = ['tr_accuracy', 'tr_precision', 'tr_recall', 'tr_f1']\n",
    "\n",
    "    val_metrics_df = pd.DataFrame(val_metrics_feat).T\n",
    "    val_metrics_df.columns = ['cv_accuracy', 'cv_precision', 'cv_recall', 'cv_f1']\n",
    "    \n",
    "    metrics_df = pd.concat([tr_metrics_df, val_metrics_df], axis = 1)\n",
    "    return metrics_df[['tr_accuracy', 'cv_accuracy', 'tr_precision', 'cv_precision',\n",
    "                       'tr_recall', 'cv_recall', 'tr_f1', 'cv_f1']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tr_accuracy</th>\n",
       "      <th>cv_accuracy</th>\n",
       "      <th>tr_precision</th>\n",
       "      <th>cv_precision</th>\n",
       "      <th>tr_recall</th>\n",
       "      <th>cv_recall</th>\n",
       "      <th>tr_f1</th>\n",
       "      <th>cv_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.877344</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.26875</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.518056</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.352939</td>\n",
       "      <td>0.366667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.863281</td>\n",
       "      <td>0.846667</td>\n",
       "      <td>0.26875</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.425581</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0.328795</td>\n",
       "      <td>0.340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.864844</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.31875</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.442646</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.369940</td>\n",
       "      <td>0.403333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.864844</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.31875</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.442646</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.369940</td>\n",
       "      <td>0.403333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.864844</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.31875</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.445201</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.370643</td>\n",
       "      <td>0.406667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.872656</td>\n",
       "      <td>0.873333</td>\n",
       "      <td>0.38750</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.486630</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.431166</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.868750</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.39375</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.470128</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.428086</td>\n",
       "      <td>0.403333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.868750</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.39375</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.470128</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.428086</td>\n",
       "      <td>0.403333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.870313</td>\n",
       "      <td>0.873333</td>\n",
       "      <td>0.41875</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.479487</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.446233</td>\n",
       "      <td>0.413333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.860156</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.38125</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.435447</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.405139</td>\n",
       "      <td>0.233333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    tr_accuracy  cv_accuracy  tr_precision  cv_precision  tr_recall  \\\n",
       "1      0.877344     0.860000       0.26875          0.35   0.518056   \n",
       "2      0.863281     0.846667       0.26875          0.35   0.425581   \n",
       "3      0.864844     0.866667       0.31875          0.45   0.442646   \n",
       "4      0.864844     0.866667       0.31875          0.45   0.442646   \n",
       "5      0.864844     0.866667       0.31875          0.45   0.445201   \n",
       "6      0.872656     0.873333       0.38750          0.45   0.486630   \n",
       "7      0.868750     0.866667       0.39375          0.45   0.470128   \n",
       "8      0.868750     0.866667       0.39375          0.45   0.470128   \n",
       "9      0.870313     0.873333       0.41875          0.45   0.479487   \n",
       "10     0.860156     0.840000       0.38125          0.25   0.435447   \n",
       "\n",
       "    cv_recall     tr_f1     cv_f1  \n",
       "1    0.450000  0.352939  0.366667  \n",
       "2    0.383333  0.328795  0.340000  \n",
       "3    0.400000  0.369940  0.403333  \n",
       "4    0.400000  0.369940  0.403333  \n",
       "5    0.400000  0.370643  0.406667  \n",
       "6    0.416667  0.431166  0.416667  \n",
       "7    0.400000  0.428086  0.403333  \n",
       "8    0.400000  0.428086  0.403333  \n",
       "9    0.416667  0.446233  0.413333  \n",
       "10   0.250000  0.405139  0.233333  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_nb = GaussianNB()\n",
    "metrics_nb_df = model_by_num_feat(clf_nb, df, feats_sorted, target, num_feat = 10)\n",
    "metrics_nb_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the top 9 features yields a model with the highest recall and precision, with high accuracy that does not overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature tuning: passing in all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passing in all features and parameter tuning\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 200, num = 11)]\n",
    "criterion = ['gini', 'entropy']\n",
    "max_features = [2, 4, 6, 10, 20, 'auto', 'log2', None]\n",
    "bootstrap = [True, False]\n",
    "\n",
    "param_grid = {'n_estimators': n_estimators,\n",
    "              'criterion': criterion,\n",
    "              'max_features': max_features,\n",
    "              'bootstrap': bootstrap,\n",
    "              'n_jobs': [-1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator found by grid search:\n",
      "RandomForestClassifier(bootstrap=False, class_weight=None,\n",
      "            criterion='entropy', max_depth=None, max_features=20,\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=150, n_jobs=-1, oob_score=False,\n",
      "            random_state=None, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "grid_search_all = GridSearchCV(RandomForestClassifier(), param_grid, scoring='recall_macro')\n",
    "grid_search_clf_all = grid_search_all.fit(df[feats_sorted], df[target])\n",
    "print(\"Best estimator found by grid search:\")\n",
    "print(grid_search_clf_all.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1.0, 1.0, 1.0, 1.0],\n",
       " [0.84000000000000008, 0.25, 0.19999999999999998, 0.22000000000000003])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_rf_all = RandomForestClassifier(**grid_search_clf_all.best_params_)\n",
    "metrics_rf_df_all = classify(clf_rf_all, df, feats_sorted, target)\n",
    "metrics_rf_df_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature tuning: passing in top three features from SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only passing in top 3 features from SelectKBest to parameter tuning\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 200, num = 11)]\n",
    "criterion = ['gini', 'entropy']\n",
    "max_features = ['auto', 'log2', None]\n",
    "bootstrap = [True, False]\n",
    "\n",
    "param_grid = {'n_estimators': n_estimators,\n",
    "              'criterion': criterion,\n",
    "              'max_features': max_features,\n",
    "              'bootstrap': bootstrap,\n",
    "              'n_jobs': [-1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator found by grid search:\n",
      "RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='log2', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=120, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "grid_search_3 = GridSearchCV(RandomForestClassifier(), param_grid, scoring='recall_macro')\n",
    "grid_search_clf_3 = grid_search_3.fit(df[feats_sorted[:3]], df[target])\n",
    "print(\"Best estimator found by grid search:\")\n",
    "print(grid_search_clf_3.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1.0, 1.0, 1.0, 1.0],\n",
       " [0.88000000000000012,\n",
       "  0.55000000000000004,\n",
       "  0.57499999999999996,\n",
       "  0.53333333333333333])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_rf_3 = RandomForestClassifier(**grid_search_clf_3.best_params_)\n",
    "metrics_rf_df_3 = classify(clf_rf_3, df, feats_sorted[:3], target)\n",
    "metrics_rf_df_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Although this is overfit, I played with the parameters and could not get better cross validation scores than these."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature tuning: passing in top four features from SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only passing in top 4 features from SelectKBest to parameter tuning\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 200, num = 11)]\n",
    "criterion = ['gini', 'entropy']\n",
    "max_features = ['auto', 'log2', None]\n",
    "bootstrap = [True, False]\n",
    "\n",
    "param_grid = {'n_estimators': n_estimators,\n",
    "              'criterion': criterion,\n",
    "              'max_features': max_features,\n",
    "              'bootstrap': bootstrap,\n",
    "              'n_jobs': [-1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator found by grid search:\n",
      "RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "grid_search_4 = GridSearchCV(RandomForestClassifier(), param_grid, scoring='recall_macro')\n",
    "grid_search_clf_4 = grid_search_4.fit(df[feats_sorted[:4]], df[target])\n",
    "print(\"Best estimator found by grid search:\")\n",
    "print(grid_search_clf_4.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1.0, 1.0, 1.0, 1.0],\n",
       " [0.87999999999999989,\n",
       "  0.40000000000000002,\n",
       "  0.55000000000000004,\n",
       "  0.4366666666666667])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_rf_4 = RandomForestClassifier(**grid_search_clf_4.best_params_)\n",
    "metrics_rf_df_4 = classify(clf_rf_4, df, feats_sorted[:4], target)\n",
    "metrics_rf_df_4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature tuning: passing in top five features from SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only passing in top 4 features from SelectKBest to parameter tuning\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 200, num = 11)]\n",
    "criterion = ['gini', 'entropy']\n",
    "max_features = ['auto', 'log2', None]\n",
    "bootstrap = [True, False]\n",
    "\n",
    "param_grid = {'n_estimators': n_estimators,\n",
    "              'criterion': criterion,\n",
    "              'max_features': max_features,\n",
    "              'bootstrap': bootstrap,\n",
    "              'n_jobs': [-1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator found by grid search:\n",
      "RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=110, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "grid_search_5 = GridSearchCV(RandomForestClassifier(), param_grid, scoring='recall_macro')\n",
    "grid_search_clf_5 = grid_search_5.fit(df[feats_sorted[:5]], df[target])\n",
    "print(\"Best estimator found by grid search:\")\n",
    "print(grid_search_clf_5.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1.0, 1.0, 1.0, 1.0],\n",
       " [0.87999999999999989, 0.40000000000000002, 0.5, 0.42000000000000004])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_rf_5 = RandomForestClassifier(**grid_search_clf_5.best_params_)\n",
    "metrics_rf_df_5 = classify(clf_rf_5, df, feats_sorted[:5], target)\n",
    "metrics_rf_df_5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make data into a dictionary again to pass to tester\n",
    "df_dict = df.to_dict('index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB(priors=None)\n",
      "\tAccuracy: 0.85393 \tPrecision: 0.48617 \tRecall: 0.39550 \tF1: 0.43617 \tF2: 0.41082\n",
      "\tTotal predictions: 14000                         \tTrue positives:  791\tFalse positives:  836                        \tFalse negatives: 1209\tTrue negatives: 11164\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Best Naive Bayes model\n",
    "chosen_feats = ['poi']\n",
    "chosen_feats.extend(feats_sorted[:9]) # add poi as the first feature\n",
    "test_classifier(clf_nb, df_dict, chosen_feats, folds = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='log2', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=120, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "\tAccuracy: 0.84869 \tPrecision: 0.50923 \tRecall: 0.45500 \tF1: 0.48059 \tF2: 0.46490\n",
      "\tTotal predictions: 13000                         \tTrue positives:  910\tFalse positives:  877                        \tFalse negatives: 1090\tTrue negatives: 10123\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3 features\n",
    "chosen_feats = ['poi']\n",
    "chosen_feats.extend(feats_sorted[:3])\n",
    "test_classifier(clf_rf_3, df_dict, chosen_feats, folds = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "\tAccuracy: 0.84892 \tPrecision: 0.51200 \tRecall: 0.38400 \tF1: 0.43886 \tF2: 0.40421\n",
      "\tTotal predictions: 13000                         \tTrue positives:  768\tFalse positives:  732                        \tFalse negatives: 1232\tTrue negatives: 10268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4 features\n",
    "chosen_feats = ['poi']\n",
    "chosen_feats.extend(feats_sorted[:4])\n",
    "test_classifier(clf_rf_4, df_dict, chosen_feats, folds = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=110, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "\tAccuracy: 0.84554 \tPrecision: 0.49715 \tRecall: 0.34850 \tF1: 0.40976 \tF2: 0.37067\n",
      "\tTotal predictions: 13000                         \tTrue positives:  697\tFalse positives:  705                        \tFalse negatives: 1303\tTrue negatives: 10295\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5 features\n",
    "chosen_feats = ['poi']\n",
    "chosen_feats.extend(feats_sorted[:5])\n",
    "test_classifier(clf_rf_5, df_dict, chosen_feats, folds = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=False, class_weight=None,\n",
      "            criterion='entropy', max_depth=None, max_features=20,\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=150, n_jobs=-1, oob_score=False,\n",
      "            random_state=None, verbose=0, warm_start=False)\n",
      "\tAccuracy: 0.81333 \tPrecision: 0.23719 \tRecall: 0.18050 \tF1: 0.20500 \tF2: 0.18956\n",
      "\tTotal predictions: 15000                         \tTrue positives:  361\tFalse positives: 1161                        \tFalse negatives: 1639\tTrue negatives: 11839\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# All features\n",
    "chosen_feats = ['poi']\n",
    "chosen_feats.extend(feats_sorted)\n",
    "test_classifier(clf_rf_all, df_dict, chosen_feats, folds = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_best = clf_rf_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('exercised_stock_options', 0.31165478901033927),\n",
       " ('total_stock_value', 0.33013998510720011),\n",
       " ('bonus', 0.3582052258824609)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature importances\n",
    "list(zip(chosen_feats[1:], clf_best.feature_importances_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dump Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump final chosen classifier\n",
    "dump_classifier_and_data(clf_best, data_dict, chosen_feats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
